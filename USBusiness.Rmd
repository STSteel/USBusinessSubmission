---
title: "US Economic Analysis"
author: "Simone Trindade Steel"
date: "02/08/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## An analysis of national economic sentiment effect on new housing offers

## 1. Introduction and executive summary

This reports is based on a study of business and industry trends in the United States 
using the US Census Bureau data available on https://www.kaggle.com/census/business-and-industry-reports.

The inspiration for this study is the hypothesis that US National level of value generation,
as an indication of economic optimism, drives the anticipation of new property demand. 

The analysis looks for regional variations in the US and attempts to predict the regional 
growth of new home construction and sales.

The main objective is to unveil whether or not there is an identifiable time lag between the perception of a buoyant economic environment and the offer of newly built houses on the market. Given that the construction sector does not have the same agility as other parts of the economy, such as retail and services, it could be important for investors, government agencies and policy makers to prevent over or under investment in the construction sector.

By identifying a time lag between stimulus and result, investment in construction could be self-regulated to avoid large oscillation in supply, which may contribute to distortions in the market, such as the so-called "housing bubbles".

This report will cover the exploration and preparation of data, the construction of alternative predictive models, and the results analysis leading to the report conclusion.

```{r set-up, include=FALSE, warning=FALSE, message=FALSE}
##########################
# 
# Preparing the environment:packages, libraries and data files
#
##########################

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(e1071)) install.packages("e1071", repos = "http://cran.us.r-project.org")
#if(!require(tidytext)) install.packages("tidytext", repos = "http://cran.us.r-project.org")
#if(!require(textdata)) install.packages("textdata", repos = "http://cran.us.r-project.org")
#if(!require(randomForest)) install.packages("randomForest", repos = "http://cran.us.r-project.org")

library(stringr)
library(tidyverse)
library(dplyr)
library(caret)
library(tinytex)
library(lubridate)
library(tidytext)
library(data.table)

library(rpart)
library(ggplot2)
library(randomForest)

options(digits = 3)    # 3 significant digits

# Loading time series data
temp <- read_file(unzip("CapstoneProject_data.csv.zip", "CapstoneProject_data.csv"))
data <-read_csv(temp, guess_max = 1000000)
df <- as.data.frame(data)
df <- df %>% mutate(value = as.numeric(value))

# Loading metadata to enable selection of Housing indicators and overall Financial results
temp <- read_file(unzip("CapstoneProject_metadata.csv.zip", "CapstoneProject_metadata.csv"))
md <-read_csv(temp)
md_df <- as.data.frame(md)

# Remove temporary variables
rm(md, data, temp)

```

## 2. Method and analysis 

## 2.1. Initial considerations

House construction is a relatively slow-moving activity. Securing funds, land and necessary permissions are traditionally extended processes. An important assumption in this analysis is that there is an interval between decision to build and houses becoming available, i.e. time lag. 

This report includes the analysis of several values for time lag, aiming to detect the interval that produces the best predictive capability for investment expansion and contraction trajectories. The time lag values chosen for this analysis will be based on a short Fibonacci sequence (1, 2, 3, 5, 8, 13 expressed and calendar years).

Another dimension of analysis is region within the United States. This is to verify the hypothesis that regional differences in dominant industries and variations in economic cycles lead to different behaviour towards real estate investment.

In summary:

a. This report uses the standard mechanism for randomly splitting the training and test sets using probability of 0.9 and 0.1, respectively.

b. The outcome of the prediction will be categorical: 1 representing above average housing offers for the region and 0 representing below average.

c. Overall accuracy was chosen as the best method for measuring success of the predictive model, i.e. maximising the proportion of correct predictions on the test set.  

d. The objectives are to identify (1) the time lag between economic indicators and housing offers and (2) the best performing predictive model or ensemble of models that maximises overall accuracy.



## 2.2. Understanding the data


The original dataset has many economic factors that will not be used in this study.

The time series that are relevant to the subject of this report are:

a. The macroeconomic indicators (named "Financial Reports") and 

b. The new housing indicators (named "New Home Sales", "New Residential Construction").

The metadata file for these two subjects provide the time series code to access the available data:

```{r, echo=FALSE, warning=FALSE, message=FALSE}


# What time series are used for new home sales and housing under construction indicators? 
housing_cat <- md_df %>% 
  filter((report=="New Residential Construction" | report=="New Home Sales"), 
         dt_code=="TOTAL",
         is_adj==0)

housing_cat %>% group_by(report) %>% summarise (number_of_timeseries=n()) %>% knitr::kable() 

# What time series are used for value creation in the financial reports (sales, revenue)? 
finance_cat <- md_df %>% 
  filter(report=="Quarterly Financial Report", 
         dt_code=="101",
         is_adj==0)

finance_cat %>% group_by(report) %>% summarise (number_of_timeseries=n()) %>% knitr::kable() 

# All activity related to new dwellings, as a proxy for expected regional demand for housing
housing_dat <- df %>% filter(time_series_code %in% housing_cat$time_series_code)

print("First 10 rows of relevant Housing Data")
head(housing_dat, 10) %>% knitr::kable()
print(c("Total rows for Housing Data: ", nrow(housing_dat)))

# All sales and revenue at national level, keeping all the aggregated numbers per industry (category_level=0)
finance_cat <- finance_cat %>% filter(category_level==0)
finance_dat <- df %>% filter(time_series_code %in% finance_cat$time_series_code)
# Separate industry category as a column
finance_dat <- finance_dat %>% mutate(industry = str_trunc(time_series_code, 3, side="right", ellipsis=""))
finance_dat <- finance_dat %>% mutate(industry = as.factor(industry))

print("First 10 rows of relevant Financial Data")
head(finance_dat, 10) %>% knitr::kable()
print(c("Total rows for Financial Data: ", nrow(finance_dat)))

```


All dates indicate the beginning of the analysis period, and they have been used to align the time series into quarterly periods - January, April, July and October.


```{r analysis, include=FALSE, warning=FALSE, message=FALSE}


# Loading the relevant time series for analysis

# Trimming the housing time series according to available financial data
housing_dat <- housing_dat %>% filter(date>=min(finance_dat$date) & date<=max(finance_dat$date))
min(housing_dat$date) == min(finance_dat$date)
max(housing_dat$date) == max(finance_dat$date)

rm(df, md_df)

# Aggregate housing data quarterly in order to align with the granularity of financial data
housing_dat <- housing_dat %>% 
  mutate(quarter = as_date(ifelse(month(date)==2 | month(date)==3,
                                               as_date(paste(as.character(year(date)),'01',as.character(day(date)), sep="-")),
                           ifelse(month(date)==5 | month(date)==6,
                                               as_date(paste(as.character(year(date)),'04',as.character(day(date)), sep="-")),
                           ifelse(month(date)==8 | month(date)==9,
                                               as_date(paste(as.character(year(date)),'07',as.character(day(date)), sep="-")),
                           ifelse(month(date)==11 | month(date)==12,
                                               as_date(paste(as.character(year(date)),'10',as.character(day(date)), sep="-")),
                                               date))))))

housing_dat %>% group_by(quarter) %>% summarise(n())

# Override date column for easier manipulation later
housing_dat <- housing_dat %>% mutate(date=quarter)

# Extract 2 letters representing the State from the time series code so that we can separate regional and national levels later
housing_dat <- housing_dat %>% mutate(region = str_trunc(time_series_code, 2, side="left", ellipsis=""))
housing_dat <- housing_dat %>% mutate(region = as.factor(region))

# Aggregating all new house activity
housing_dat <- housing_dat %>% group_by(date, region) %>% summarise(value=sum(value))
housing_dat_total <- data.frame(housing_dat)
str(housing_dat_total)


```

The graphs below summarise the US national totals, and show the disruption created by the 2008 crisis. Following the crisis, revenue resumed its upwards trajectory, as seen with broader economic recovery. 


```{r analysis2008-graphs, echo=FALSE, warning=FALSE, message=FALSE}

# Visualising the effects of National value generation on the anticipation of housing demand (i.e. new build) regionally.


# Firstly, the 2008 housing market shock is clearly visible in both the financial and housing data
graph_fin <- finance_dat %>% group_by(date) %>% summarise(value_generated=sum(value)) %>% 
  ggplot(aes(x=date, y=value_generated)) + 
  ylab("Sales and Revenue in USD Millions") +
  ggtitle("US total from Q4/2000 to Q1/2017") +
  geom_line() + geom_vline(xintercept=date("2008-09-15"), colour="red") +
  annotation_custom(grid::linesGrob())
graph_fin

avg <- housing_dat %>% ungroup() %>% filter(region=="US") %>% select(v=value) %>% summarise(mean(v))
graph_h_us <- housing_dat_total %>% filter(region=="US") %>% 
   group_by(region, date) %>% summarise(new_builds=sum(value)) %>% 
   ggplot(aes(x=date, y=new_builds)) + 
   ylab("Thousands of new housing units") +
   ggtitle("US total from Q4/2000 to Q1/2017") +
   geom_point() + geom_hline(yintercept=as.numeric(avg), colour="blue") +
   geom_vline(xintercept=date("2008-09-15"), colour="red")
graph_h_us

```


The regional graphs, however, show that new housing construction and offering vary along each individual regional average that appears not related to the broader revenue generation at national level.

Looking closer at each region, the house offer variability in the South is far greater than the other regions. The Northeast is stable relatively to the national income fluctuations.

```{r analysisregion-graphs, echo=FALSE, warning=FALSE, message=FALSE}

# Looking closer at each region, the house offer variability in the South is far greater than the other regions.
# The Northeast is stable relatively to the national income fluctuations.
graph_h_reg <- housing_dat_total %>% filter(region!="US") %>% 
  group_by(region, date) %>% summarise(new_builds=sum(value)) %>% 
  ggplot(aes(x=date, y=new_builds, colour=region)) + 
  ylab("Thousands of new housing units") +
  ggtitle("Total per region from Q4/2000 to Q1/2017") +
  geom_line() 
graph_h_reg

```


In order to understand what drives an increase and decrease of new housing, this analysis will categorise new housing offers above average as 1, and below average as 0, relative to each regional average.


## 2.3. Preparing data for analysis

Several steps are performed here:

(1) Creating different time lag data and aligning them with income generation and house construction. As explained earlier, a short Fibonacci sequence is going to be used to explore different time lags: 1, 2, 3, 5, 8 and 13 years.

(2) Removing aggregated US National data points in order not to double count properties.

(3) Preparing regional averages, given that the variations are significant between regions.

(4) Introducing industry classification, given their regional variation.

Industry codes are:


```{r preparing-data, echo=FALSE, warning=FALSE, message=FALSE}

# Industry codes and description
print("Industry codes and description")
finance_cat %>% select(Code=cat_code, Description=cat_desc) %>% knitr::kable()

# Adding a time lag in years (1, 2, 3, 5, 8, 13) between sentiment of growth (sales, revenue) and new house activity

finance_dat <- finance_dat %>% mutate(lag_1y = as_date(paste(as.character(year(date)+1), as.character(month(date)),as.character(day(date)), sep="-")),
                                      lag_2y = as_date(paste(as.character(year(date)+2), as.character(month(date)),as.character(day(date)), sep="-")),
                                      lag_3y = as_date(paste(as.character(year(date)+3), as.character(month(date)),as.character(day(date)), sep="-")),
                                      lag_5y = as_date(paste(as.character(year(date)+5), as.character(month(date)),as.character(day(date)), sep="-")),
                                      lag_8y = as_date(paste(as.character(year(date)+8), as.character(month(date)),as.character(day(date)), sep="-")),
                                      lag_13y = as_date(paste(as.character(year(date)+13), as.character(month(date)),as.character(day(date)), sep="-")))


print("First 10 rows of relevant Financial Data, with extra columns representing time lag")
head(finance_dat, 10)

# Matrix for prediction, aligning all values by quarter: 
# anchoring the year of housing offer and bringing in financial results according to time lag.

temp <- left_join(housing_dat_total, finance_dat, by= c("date"="lag_1y"))
temp <- temp %>% mutate(new_houses_K = value.x, nat_income_M_1y = value.y) %>% 
  dplyr::select(date, region, industry, new_houses_K, nat_income_M_1y)

temp <- left_join(temp, finance_dat, by= c("date"="lag_2y", "industry"="industry"))
temp <- temp %>% mutate(nat_income_M_2y = value) %>% 
  dplyr::select(date, region, industry, new_houses_K, 
                nat_income_M_1y, nat_income_M_2y)

temp <- left_join(temp, finance_dat, by= c("date"="lag_3y", "industry"="industry"))
temp <- temp %>% mutate(nat_income_M_3y = value) %>% 
  dplyr::select(date, region, industry, new_houses_K,
                nat_income_M_1y, nat_income_M_2y, nat_income_M_3y)

temp <- left_join(temp, finance_dat, by= c("date"="lag_5y", "industry"="industry"))
temp <- temp %>% mutate(nat_income_M_5y = value) %>% 
  dplyr::select(date, region, industry, new_houses_K, 
                nat_income_M_1y, nat_income_M_2y, nat_income_M_3y, nat_income_M_5y)


temp <- left_join(temp, finance_dat, by= c("date"="lag_8y", "industry"="industry"))
temp <- temp %>% mutate(nat_income_M_8y = value) %>% 
  dplyr::select(date, region, industry, new_houses_K,  
                nat_income_M_1y, nat_income_M_2y, nat_income_M_3y, nat_income_M_5y, nat_income_M_8y)

temp <- left_join(temp, finance_dat, by= c("date"="lag_13y", "industry"="industry"))
temp <- temp %>% mutate(nat_income_M_13y = value) %>% 
  dplyr::select(date, region, industry, new_houses_K,  
                nat_income_M_1y, nat_income_M_2y, nat_income_M_3y, nat_income_M_5y, nat_income_M_8y, nat_income_M_13y)

# Removing rows that have no industry-level information
temp <- temp %>% filter(!is.na(industry))

print("Number of data points available by industry when the different time lags were introduced")
temp %>% group_by(industry) %>% summarise(sum1y = sum(!is.na(nat_income_M_1y)),
                                          sum2y = sum(!is.na(nat_income_M_2y)),
                                          sum3y = sum(!is.na(nat_income_M_3y)),
                                          sum5y = sum(!is.na(nat_income_M_5y)),
                                          sum8y = sum(!is.na(nat_income_M_8y)),
                                          sum13y = sum(!is.na(nat_income_M_13y))) %>% knitr::kable()


# Removing all US housing totals because the analysis is regional only
dataset <- temp %>% filter(region!="US")
rm(temp)

```

Now that the datasets are aligned in quarterly periods and by each of the hypothesis of time lag, the following graphs show some interesting relationships that will inform choices for model-based predictions.

Each graph is organised to show the relationship between income (x axis) and new building activity (y axis), in vertical facets for each region and horizontal facets by industry. The shades in the graph represent time in calendar years.

When looking at the same point in time, pre-2008 (darker shades) data shows new housing activity was higher in the South and West regions. But over time, it seems negatively influenced by income. 

Does this support the notion of a time lag between income from sales and revenue rising and new housing activity occurring?

The graphs also show (just as the table above) that there are no data points for 8- and 13-year lag for Information and Professional and Technical services, as these are relatively new industries from the point of view of census records. Due to the lack of significant amount of data, 8- and 13-year lag will not be considered in the building of predictive models.


```{r visualising-data, echo=FALSE, warning=FALSE, message=FALSE}

# Pre-2008 (darker shades), new housing activity was higher in the South and West regions.
# But over time, it seems negatively influenced by income, especially in the Mining industry
# This shows that there are no data points for 8- and 13-year lag for Information and Professional and Technical services.
# Therefore, 8- and 13-year lag will not be considered in the building of predictive models.

dataset %>% 
  ggplot(aes(x=log10(nat_income_M_1y), y=new_houses_K, colour=year(date))) + 
  theme(axis.text = element_text(size = 8))  +
  theme(axis.title = element_text(size = 10))  +
  theme(text = element_text(size = 8))  +
  xlab("Sales and Revenue in USD Millions (log10), with 1 year income lag") +
  ylab("New Housing in Thousands of Units") +
  ggtitle("Revenue and New Housing, per region and industry") +
  geom_point()  + 
  facet_grid(industry ~ region)

dataset %>% 
  ggplot(aes(x=log10(nat_income_M_2y), y=new_houses_K, colour=year(date))) + 
  theme(axis.text = element_text(size = 8))  +
  theme(axis.title = element_text(size = 10))  +
  theme(text = element_text(size = 8))  +
  xlab("Sales and Revenue in USD Millions (log10), with 2 years income lag") +
  ylab("New Housing in Thousands of Units") +
  ggtitle("Revenue and New Housing, per region and industry") +
  geom_point()  + 
  facet_grid(industry ~ region)

dataset %>% 
  ggplot(aes(x=log10(nat_income_M_3y), y=new_houses_K, colour=year(date))) + 
  theme(axis.text = element_text(size = 8))  +
  theme(axis.title = element_text(size = 10))  +
  theme(text = element_text(size = 8))  +
  xlab("Sales and Revenue in USD Millions (log10), with 3 years income lag") +
  ylab("New Housing in Thousands of Units") +
  ggtitle("Revenue and New Housing, per region and industry") +
  geom_point()  + 
  facet_grid(industry ~ region)



dataset %>% 
  ggplot(aes(x=log10(nat_income_M_5y), y=new_houses_K, colour=year(date))) + 
  theme(axis.text = element_text(size = 8))  +
  theme(axis.title = element_text(size = 10))  +
  theme(text = element_text(size = 8))  +
  xlab("Sales and Revenue in USD Millions (log10), with 5 years income lag") +
  ylab("New Housing in Thousands of Units") +
  ggtitle("Revenue and New Housing, per region and industry") +
  geom_point()  + 
  facet_grid(industry ~ region)


dataset %>% 
  ggplot(aes(x=log10(nat_income_M_8y), y=new_houses_K, colour=year(date))) + 
  theme(axis.text = element_text(size = 8))  +
  theme(axis.title = element_text(size = 10))  +
  theme(text = element_text(size = 8))  +
  xlab("Sales and Revenue in USD Millions (log10), with 8 years income lag") +
  ylab("New Housing in Thousands of Units") +
  ggtitle("Revenue and New Housing, per region and industry") +
  geom_point()  + 
  facet_grid(industry ~ region)

dataset %>% 
  ggplot(aes(x=log10(nat_income_M_13y), y=new_houses_K, colour=year(date))) + 
  theme(axis.text = element_text(size = 8))  +
  theme(axis.title = element_text(size = 10))  +
  theme(text = element_text(size = 8))  +
  xlab("Sales and Revenue in USD Millions (log10), with 13 years income lag") +
  ylab("New Housing in Thousands of Units") +
  ggtitle("Revenue and New Housing, per region and industry") +
  geom_point()  + 
  facet_grid(industry ~ region)

dataset <- dataset %>% dplyr::select(date, region, industry, new_houses_K,  
                                     nat_income_M_1y, nat_income_M_2y, nat_income_M_3y, nat_income_M_5y)


```

Given that there are considerable differences in new housing per region, the trend will be added to the dataset relative to regional means.

```{r trend, echo=FALSE, warning=FALSE, message=FALSE}

###################
# Considerable differences in construction output per region will require the analysis to be centred on regional means
###################

housing_avg <- dataset %>% group_by(region) %>% summarise(avg = mean(new_houses_K))
dataset <- inner_join(dataset, housing_avg, by="region")

# Trend = 1 meaning positive, if more new houses than average are predicted
# Trend = 0 meaning negative, if fewer new houses than average are predicted

dataset <- dataset %>% mutate(trend=as.factor(ifelse(new_houses_K>=avg,1,0)))

print("First 10 rows showing the addition of Trend (0 or 1) to the dataset for each region")
head(dataset)


```


## 2.4. Making predictions and finding optimal time lag parameter

This report aims to demonstrate that the regional trends of new house construction is lagging 
the sentiment of a positive economic position, as observed by financial reports on sales, invoicing and revenue at the national level.

In order to do that, the concept of positive or negative trend was introduced. Positive trend means
that regional construction is above historical average, and negative trend means below average.

The models that appeared most appropriate for this exercise were GLM, KNN and Random Forest. An ensemble of models was also introduced to verify if it could improve on the predictions of individual models.

As mentioned at the beginning of this report, the dataset for training the models and testing them was randomly split from the original with probability of 0.9 and 0.1, respectively. Each of the models was fit and tested for time lags of 1, 2, 3 and 5 years.


```{r prediction, include=FALSE, warning=FALSE, message=FALSE}

# Splitting training and test datasets

# The dataset will be split into Training (0.9) and Validation (0.1) sets for fitting the model and testing, respectively.

set.seed(1, sample.kind="Rounding")

test_index <- createDataPartition(y = dataset$new_houses_K, times = 1, p = 0.1, list = FALSE)
train_ds <- dataset[-test_index[,1],]
test_ds <- dataset[test_index[,1],]

# Training 
lag <- c(1,2,3,5)   # Time lag expressed as reduced Fibonacci sequence

res <- sapply(lag, function(i) {

  train_ds_clean <- train_ds %>% dplyr::select(trend, region, industry,
                                 nat_income=c(paste("nat_income_M_",i, "y", sep=""))) %>%
                                 filter(!is.na(nat_income)) # Removing NA in the lagged income
  
  x <- train_ds_clean %>% dplyr::select(region, industry, nat_income)
    
  y <- train_ds_clean$trend # Outcome used to train the model
  
  # Align names of columns between Training and Testing 
  # (rename columns to match the name of the national income with time lag in the loop)
  # (ensure there are no NAs in predictors)
  test_ds_clean <- test_ds %>% dplyr::select(trend, region, industry, nat_income=c(paste("nat_income_M_",i,"y", sep=""))) %>%
                               filter(!is.na(nat_income)) # Removing NA in the lagged income
  
  # ============= GLM ==============
  fit <- train(x, y, method = "glm")
  fit$results
  # Testing 
  y_hat_GLM <- predict(fit, test_ds_clean) 
  y_hat <- y_hat_GLM
  acc <- confusionMatrix(data = y_hat, reference = test_ds_clean$trend)$overall["Accuracy"]
  
  res <- data.frame() # Initiate as empty data frame of results 
  res <- rbind(res, data.frame(Model=paste("GLM",i, "year_lag", sep="_"), Accuracy=acc))

  # ========= Random Forest ========
  fit <- randomForest(y ~ ., data = x, nodesize = 50, maxnodes = 25)
  fit$importance
  # Testing
  y_hat_RF <- predict(fit, test_ds_clean) 
  y_hat <- y_hat_RF
  acc <- confusionMatrix(data = y_hat, reference = test_ds_clean$trend)$overall["Accuracy"]
  res <- rbind(res, data.frame(Model=paste("RandomForest",i, "year_lag", sep="_"), Accuracy=acc))
  
  # ========= KNN ============
  
  ks <- seq(1, 51, 3)
  F_1 <- sapply(ks, function(k){
    fit <- knn3(y ~ ., data = x, k = k)
    y_hat <- predict(fit, test_ds_clean, type = "class") %>% 
      factor(levels = levels(test_ds_clean$trend))
    F_meas(data = y_hat, reference = test_ds_clean$trend)
  })
  max(F_1)
  k_max <- ks[which.max(F_1)]
  print(paste("For time lag =", i, "year(s), the optimal k parameter for KNN =",k_max, sep=" "))
  plot(ks, F_1)
  fit <- knn3(y ~ ., data = x, k= k_max)
  y_hat_KNN <- predict(fit, test_ds_clean, type = "class")
  y_hat <- y_hat_KNN
  acc <- confusionMatrix(data = y_hat, reference = test_ds_clean$trend)$overall["Accuracy"]
  res <- rbind(res, data.frame(Model=paste("KNN", k_max,i, "year_lag", sep="_"), Accuracy=acc))
  
  
  # ======= Ensemble ===========
  # ENSEMBLE of all models, i.e. looking at all results and selecting the predominant one#
  y_set <- data.frame(y_hat_GLM = as.integer(ifelse(y_hat_GLM==1, 1, 0)),
                      y_hat_KNN = as.integer(ifelse(y_hat_KNN==1, 1, 0)),
                      y_hat_RF = as.integer(ifelse(y_hat_RF==1, 1, 0)))
  
  y_set <- y_set %>% mutate(ens_y_hat = round((y_hat_GLM + y_hat_KNN + y_hat_RF)/3))
  
  y_set <- y_set %>% mutate(y_hat = as.factor(ens_y_hat))
  levels(y_set$y_hat) <- levels(test_ds_clean$trend)
  acc <- confusionMatrix(y_set$y_hat, test_ds_clean$trend)$overall["Accuracy"]
  res <- rbind(res, data.frame(Model=paste("Ensemble",i, "year_lag", sep="_"), Accuracy=acc))
  
  # Table with combined results of models for all time lags  
  # res %>% knitr::kable()
  pull(res)
}) 

```

## 3. Results

The maximum accuracy of 0.839 was obtained by the KNN model with k=4 and a time lag of 5 years between income and new housing activity.

The accuracy of each model and time lag combination were gathered during the execution of the R script and are displayed below as a table and a plot graph. 

```{r diplay-predictions, echo=FALSE, warning=FALSE, message=FALSE}

colnames(res) <- c("1_year_lag","2_year_lag","3_year_lag","5_year_lag")
rownames(res) <- c("GLM", "RandomForest","KNN", "Ensemble")

print("Accuracy results of predictive models built and tested in this report")
res %>% knitr::kable()

graph_results <- as.data.frame(res) %>% 
                 rownames_to_column(var="Model") %>%
                 gather(key="Lag", value="Accuracy", -Model) %>%
                 ggplot(aes(x=Lag, y=Accuracy, colour=Model)) + 
                 geom_point() 
graph_results

```


## 4. Conclusion

This report shows that a predictive model can be used to determine the volume, relative to the regional average, of new houses that will be offered 5 years later based on the economic outlook in the United States. The models were built to take into account regional and industry differences and the best performing one was able to produce a maximum accuracy 0.839.

Although accuracy is not particularly high, this may still have useful applications for investors and policy makers to prevent over and under investment, which can have damaging effects in the economy because of the illiquid nature of real estate assets.

This report has several limitations, notably:

(a) As with any macroeconomic analysis, the inter-dependencies and correlations between indicators are complex and were not fully explored in this report.

(b) There is a relatively small number of data points available, especially for recently developed industries such as Information, Professional and Technical Services sectors.

(c) Other predictive models and techniques not explored in this report may yield better accuracy results.


Future studies based on this approach could enrich the understanding between perception of prosperity and attitude towards real estate investment, such as tax structure changes, specific cyclical nature of each industry and internal migration of workforce.

